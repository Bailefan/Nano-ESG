{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bertopic import BERTopic\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from company_info import company_info_list\n",
    "\n",
    "from helper_functions import filter_data\n",
    "\n",
    "# Variable used in plots later\n",
    "textfont_size = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DATA\n",
    "data = pd.read_json('data/full_data/nano_esg.json', lines=True)\n",
    "\n",
    "start_date = '2023-01-01'\n",
    "end_date = '2024-09-16'\n",
    "\n",
    "companies = list(data['company'].unique())\n",
    "\n",
    "sent_dict = {'positive': 1, 'negative': -1, 'neutral': 0}\n",
    "aspect_filters = ['environmental', 'social', 'governance']\n",
    "\n",
    "data['sentiment_int'] = data['sentiment'].apply(lambda x: sent_dict[x])\n",
    "\n",
    "#For plots\n",
    "aspect_colors = {'environmental': 'forestgreen', 'social': 'cornflowerblue', 'governance': 'darkmagenta'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Embedding Model used for BERTopic\n",
    "sentence_model = SentenceTransformer('jinaai/jina-embeddings-v2-base-de', trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell creates topics based on the german summaries + the german keywords returned by the LLM\n",
    "# In order to get english topic representations, it is possible to use the 'summary_en' field instead of 'summary'\n",
    "# In this case the topics will be created only based on the english summaries, without the LLM-provided keywords, so their quality might be worse\n",
    "summary_field = 'summary'\n",
    "# summary_field = 'summary_en'\n",
    "\n",
    "# Overwrite companies - processing all of them can take a bit of time\n",
    "companies = ['vw'] #'bayer', 'bmw', 'siemens'\n",
    "topic_aspect_filters = ['all']\n",
    "\n",
    "company_topics = {}\n",
    "for company in companies:\n",
    "    print(company)\n",
    "    company_data = data[data['company'] == company]\n",
    "    aspect_topics = {}\n",
    "    for aspect in topic_aspect_filters:\n",
    "        if aspect == 'all':\n",
    "            aspect_data = company_data\n",
    "        else:\n",
    "            aspect_data = company_data[company_data['aspect'] == aspect]\n",
    "\n",
    "        #remove company name from keywords\n",
    "        keyword_filter = company_info_list[company]['keyword_filter']\n",
    "        aspect_data['keywords'] = aspect_data['keywords'].apply(lambda x: [i for i in x if i.lower() not in [j.lower() for j in keyword_filter]])\n",
    "\n",
    "        timestamps = aspect_data['date'].to_list()\n",
    "        # Note that we only have the keywords returned by the LLM in german\n",
    "        if summary_field == 'summary':\n",
    "            articles = [i[summary_field] + ' - ' + ', '.join(i['keywords']) for id, i in aspect_data.iterrows()]\n",
    "        elif summary_field == 'summary_en':\n",
    "            articles = aspect_data[summary_field].to_list()\n",
    "\n",
    "        if not articles:\n",
    "            continue\n",
    "\n",
    "        # Create a BERTopic model\n",
    "        topic_model = BERTopic(embedding_model=sentence_model, verbose=True)\n",
    "        try:\n",
    "            topics, probs = topic_model.fit_transform(articles)\n",
    "        except Exception as e:\n",
    "            print(f'Error for {company} and {aspect}: {e}')\n",
    "            continue\n",
    "        topic_info = topic_model.get_topic_info()\n",
    "        topic_dict = {'topics': topics, 'probs': probs, 'timestamps': timestamps, 'articles': articles, 'topic_info': topic_info}\n",
    "        aspect_topics[aspect] = topic_dict\n",
    "    company_topics[company] = aspect_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine Mean Relevance, Mean Sentiment and more for each topic\n",
    "\n",
    "a = 'all'\n",
    "company_articles = {}\n",
    "for c in companies:\n",
    "    topic_subset = company_topics[c][a]\n",
    "    c_data = data[data['company'] == c]\n",
    "    c_data['topics'] = topic_subset['topics']\n",
    "\n",
    "    topic_basis = 'topics'\n",
    "\n",
    "    topic_rel_score = {}\n",
    "    topic_mean_sent = {}\n",
    "    topic_aspects = {}\n",
    "    topic_dates = {}\n",
    "    num_articles_last_months = {}\n",
    "    for topic_number in topic_subset['topic_info']['Topic']:\n",
    "        topic_rel_score[topic_number] = np.mean(c_data[c_data[topic_basis] == topic_number]['relevance_score'])\n",
    "        topic_mean_sent[topic_number] = np.mean(c_data[c_data[topic_basis] == topic_number]['sentiment_int'])\n",
    "        topic_aspects[topic_number] = c_data[c_data[topic_basis] == topic_number][['aspect']].value_counts(normalize=True).to_dict()\n",
    "        topic_dates[topic_number] = pd.Timestamp(c_data[c_data[topic_basis] == topic_number]['date'].astype('int64').mean())\n",
    "        # The following determines the number of recently published articles for each topic\n",
    "        num_articles_last_months[topic_number] = c_data[(c_data[topic_basis] == topic_number) & (c_data['date'] >= '2024-08-01')]['volume'].count()\n",
    "\n",
    "    topic_subset['topic_info']['Mean_Relevance'] = topic_subset['topic_info'].apply(lambda x: topic_rel_score[x['Topic']], axis=1)\n",
    "    topic_subset['topic_info']['Mean_Sentiment'] = topic_subset['topic_info'].apply(lambda x: topic_mean_sent[x['Topic']], axis=1)\n",
    "    topic_subset['topic_info']['Aspects'] = topic_subset['topic_info'].apply(lambda x: topic_aspects[x['Topic']], axis=1)\n",
    "    topic_subset['topic_info']['Mean_Date'] = topic_subset['topic_info'].apply(lambda x: topic_dates[x['Topic']], axis=1)\n",
    "    topic_subset['topic_info']['Recent_Articles'] = topic_subset['topic_info'].apply(lambda x: num_articles_last_months[x['Topic']], axis=1)\n",
    "\n",
    "    company_topics[c][a] = topic_subset\n",
    "    company_articles[c] = c_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 'vw'\n",
    "a = 'all'\n",
    "topic_subset = company_topics[c][a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the 20 most relevant topics\n",
    "topic_subset['topic_info'].sort_values('Mean_Relevance', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fig 4: Positive & Negative Articles per month of Topic related to forced labor in China's Xinjiang Province"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the most relevant topic containing the keyword 'xinjiang'\n",
    "# Topic determination has random elements, so the resulting graph might differ slightly from the version in the paper\n",
    "sorted_topics = topic_subset['topic_info'].sort_values('Mean_Relevance', ascending=False)\n",
    "topic_num = sorted_topics[sorted_topics['Name'].str.contains('xinjiang', case=False)]['Topic'].values[0]\n",
    "\n",
    "# Alternatively, it is possible to manually select a topic by its number after browsing the topic info above\n",
    "# topic_num = 6\n",
    "\n",
    "print(topic_subset['topic_info'][topic_subset['topic_info']['Topic'] == topic_num]['Name'])\n",
    "\n",
    "topic_data = company_articles[c][[i == topic_num for i in topic_subset['topics']]]\n",
    "print(topic_data['aspect'].value_counts(normalize=True))\n",
    "\n",
    "filter_topic_data = filter_data(topic_data, None, None)\n",
    "\n",
    "topic_aspect_data_pos = {}\n",
    "topic_aspect_data_neg = {}\n",
    "topic_aspect_data_neut = {}\n",
    "for aspect in aspect_filters:\n",
    "    topic_aspect_data_pos[aspect] = filter_topic_data[(filter_topic_data['aspect'] == aspect) & (filter_topic_data['sentiment'] == 'positive')].resample('M', on='date')['sentiment_int'].sum()\n",
    "    topic_aspect_data_neg[aspect] = filter_topic_data[(filter_topic_data['aspect'] == aspect) & (filter_topic_data['sentiment'] == 'negative')].resample('M', on='date')['sentiment_int'].sum()\n",
    "    topic_aspect_data_neut[aspect] = filter_topic_data[(filter_topic_data['aspect'] == aspect) & (filter_topic_data['sentiment'] == 'neutral')].resample('M', on='date')['sentiment_int'].sum()\n",
    "\n",
    "relevance_data = filter_topic_data.resample('M', on='date')['relevance_score'].mean()\n",
    "\n",
    "######################## FIGURE ########################\n",
    "\n",
    "# Create traces for each category (positive and negative stacked bars)\n",
    "fig = go.Figure()\n",
    "\n",
    "# Adding positive sentiment bars for each category\n",
    "for aspect_filter in aspect_filters:\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=list(topic_aspect_data_pos[aspect_filter].index.to_period('M').to_timestamp()),\n",
    "        y=topic_aspect_data_pos[aspect_filter],\n",
    "        name=aspect_filter.title(),\n",
    "        offsetgroup=1,\n",
    "        # legendgroup=f'{category}',\n",
    "        marker_color=aspect_colors[aspect_filter],\n",
    "        hovertemplate=f'{aspect_filter} Positive: %{{y}}<extra></extra>',\n",
    "        showlegend=False,\n",
    "        yaxis='y1',\n",
    "    ))\n",
    "\n",
    "# Adding negative sentiment bars for each category\n",
    "for aspect_filter in aspect_filters:\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=list(topic_aspect_data_neg[aspect_filter].index.to_period('M').to_timestamp()),\n",
    "        y=topic_aspect_data_neg[aspect_filter],\n",
    "        name=aspect_filter.title(),\n",
    "        offsetgroup=2,\n",
    "        # legendgroup=f'{category}',\n",
    "        marker_color=aspect_colors[aspect_filter],\n",
    "        hovertemplate=f'{aspect_filter} Negative: %{{y}}<extra></extra>',\n",
    "        showlegend=True,\n",
    "        yaxis='y1',\n",
    "    ))\n",
    "\n",
    "# Update layout for visual styling\n",
    "fig.update_layout(\n",
    "    barmode='relative',\n",
    "    title=f\"Topic - {topic_subset['topic_info'][topic_subset['topic_info']['Topic'] == topic_num]['Representation'].values[0]}\",\n",
    "    xaxis=dict(title='Time'),\n",
    "    yaxis=dict(title='Number of Neg&Pos Articles'),\n",
    "    bargap=0.2,\n",
    "    height=500,\n",
    "    width=1500,\n",
    "    # font=dict(size=textfont_size),\n",
    "    legend=dict(\n",
    "        # x=0.2,\n",
    "        # y=0.75,\n",
    "        # xanchor='right',  # Anchor the legend to the left\n",
    "        # yanchor='bottom',  # Anchor the legend to the middle\n",
    "        bgcolor='rgba(255, 255, 255, 0.8)',  # Optional: set a background color for better visibility\n",
    "        bordercolor='black',  # Optional: set border color\n",
    "        borderwidth=1,  # Optional: set border width\n",
    "        font = dict(size = textfont_size),\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate the two months highlighted in Fig. 4 in the Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the example in the paper: Look at the positive summaries released in December 2023\n",
    "filter_topic_data[(filter_topic_data['date'] >= '2023-11-30') & (filter_topic_data['date'] <= '2023-12-31')][['date', 'sentiment', 'summary_en']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_topic_data[(filter_topic_data['date'] >= '2024-01-31') & (filter_topic_data['date'] <= '2024-02-28')][['date', 'sentiment', 'summary_en']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
